{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.620937Z",
     "iopub.status.busy": "2023-10-22T21:35:23.620495Z",
     "iopub.status.idle": "2023-10-22T21:35:23.631021Z",
     "shell.execute_reply": "2023-10-22T21:35:23.629521Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.620907Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train dataset on local device\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.810694Z",
     "iopub.status.busy": "2023-10-22T21:35:23.809640Z",
     "iopub.status.idle": "2023-10-22T21:35:23.821621Z",
     "shell.execute_reply": "2023-10-22T21:35:23.820696Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.810630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying to figure the amount of nan values\n",
    "count = train.isna().sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.842668Z",
     "iopub.status.busy": "2023-10-22T21:35:23.841510Z",
     "iopub.status.idle": "2023-10-22T21:35:23.852294Z",
     "shell.execute_reply": "2023-10-22T21:35:23.851148Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.842631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying to figure the amount of nan values\n",
    "count = test.isna().sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.860296Z",
     "iopub.status.busy": "2023-10-22T21:35:23.859101Z",
     "iopub.status.idle": "2023-10-22T21:35:23.872725Z",
     "shell.execute_reply": "2023-10-22T21:35:23.871179Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.860246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing all nan values of age with mean age for train\n",
    "mean_age = train[\"Age\"].mean()\n",
    "train['Age'].fillna(mean_age, inplace=True)\n",
    "count = train.isna().sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.884331Z",
     "iopub.status.busy": "2023-10-22T21:35:23.883896Z",
     "iopub.status.idle": "2023-10-22T21:35:23.895320Z",
     "shell.execute_reply": "2023-10-22T21:35:23.894447Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.884297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing all nan values of age with mean age for test\n",
    "mean_age = test[\"Age\"].mean()\n",
    "test['Age'].fillna(mean_age, inplace=True)\n",
    "count = test.isna().sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.904758Z",
     "iopub.status.busy": "2023-10-22T21:35:23.904386Z",
     "iopub.status.idle": "2023-10-22T21:35:23.916337Z",
     "shell.execute_reply": "2023-10-22T21:35:23.915172Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.904727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing all nan values embark with the mode in train\n",
    "mode_embark = train['Embarked'].mode()[0]  \n",
    "train['Embarked'].fillna(mode_embark, inplace=True)\n",
    "count = train.isna().sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.922642Z",
     "iopub.status.busy": "2023-10-22T21:35:23.921738Z",
     "iopub.status.idle": "2023-10-22T21:35:23.934067Z",
     "shell.execute_reply": "2023-10-22T21:35:23.932438Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.922559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing all nan values of age with mean age for test\n",
    "mean_age = test[\"Fare\"].mean()\n",
    "test['Fare'].fillna(mean_age, inplace=True)\n",
    "count = test.isna().sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:35:23.949962Z",
     "iopub.status.busy": "2023-10-22T21:35:23.949605Z",
     "iopub.status.idle": "2023-10-22T21:35:23.975079Z",
     "shell.execute_reply": "2023-10-22T21:35:23.973932Z",
     "shell.execute_reply.started": "2023-10-22T21:35:23.949923Z"
    }
   },
   "outputs": [],
   "source": [
    "#dropping name and ticket(cuz unique and doesnt help with data analysis)\n",
    "#dropping cabin cuz 75% values are nan\n",
    "test_passenger_id = test.values[:,0]\n",
    "# print(train.columns)\n",
    "# print(test_passenger_id)\n",
    "train = train.drop(['Name', 'Cabin', 'Ticket', 'PassengerId'], axis=1)\n",
    "test = test.drop(['Name', 'Cabin', 'Ticket', 'PassengerId'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train.values[:,0]\n",
    "train = train.drop('Survived', axis=1)\n",
    "train_features = train.values\n",
    "\n",
    "\n",
    "\n",
    "#print(test.columns)\n",
    "#Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')\n",
    "\n",
    "test_features = test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 'male' '12-24 years old' '1-4 sibsp members' '0 parch members'\n",
      " 'Fare Under 10 ' 'S']\n"
     ]
    }
   ],
   "source": [
    "#implement brackets for training set \n",
    "\n",
    "#print(train.columns)\n",
    "#Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')\n",
    "\n",
    " \n",
    "\n",
    "#Age:{Under 12 years old, 12-24 years old, 25-44 years old , 45-64 years old , 65 or older} \n",
    "#Age is index 2 \n",
    "\n",
    "for i in train_features:\n",
    "    get_age = int(i[2])\n",
    "    \n",
    "    #print(get_age)\n",
    "    if (get_age <= 11): #Under 12 years old\n",
    "        i[2] = \"Under 12 years old\" \n",
    "        continue\n",
    "        \n",
    "    if (12 <= get_age <= 24):\n",
    "        i[2] = \"12-24 years old\" \n",
    "        continue\n",
    "        \n",
    "    elif (25 <= get_age <= 44):\n",
    "        i[2] = \"25-44 years old\" \n",
    "        continue\n",
    "    \n",
    "    elif (45 <= get_age <= 64):\n",
    "        i[2] = \"45-64 years old\" \n",
    "        continue\n",
    "        \n",
    "    \n",
    "    elif (get_age >= 65):\n",
    "        i[2] = \"65 years or older\" \n",
    "        continue\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "#now sibsp: { 0 members,  1-4 members,  5+  members}\n",
    "#sibsp is index 3\n",
    "\n",
    "for i in train_features:\n",
    "    get_sibsp = int(i[3])\n",
    "    \n",
    "    if(get_sibsp == 0):\n",
    "        i[3] = \"0 sibsp members\"\n",
    "    \n",
    "    elif(1 <= get_sibsp <= 4):\n",
    "        i[3] = \"1-4 sibsp members\"\n",
    "    \n",
    "    elif(get_sibsp >= 5):\n",
    "        i[3] = \"5+ sibsp members\"\n",
    "        \n",
    "    \n",
    "#print(train_features[:,4])    \n",
    "\n",
    "\n",
    "#now parch:  0 members,  1-4 members,  5+  members}\n",
    "# parch is index 4\n",
    "for i in train_features:\n",
    "    get_parch = int(i[4])\n",
    "    \n",
    "    if(get_parch  == 0):\n",
    "        i[4] = \"0 parch members\"\n",
    "    \n",
    "    elif(1 <= get_parch  <= 4):\n",
    "        i[4] = \"1-4 parch members\"\n",
    "    \n",
    "    elif(get_parch  >= 5):\n",
    "        i[4] = \"5+ parch members\"\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#now fare: { under 10,11-30, 31+}\n",
    "#fare is index 5\n",
    "for i in train_features:\n",
    "    get_fares = int(i[5])\n",
    "    \n",
    "    if (get_fares <= 10):\n",
    "        i[5] = \"Fare Under 10 \"\n",
    "    \n",
    "    elif (11 <= get_fares <= 30):\n",
    "        i[5] = \"Fare 11-30\"\n",
    "        \n",
    "    elif (get_fares >= 31):\n",
    "        i[5] = \"Fare 31+\"\n",
    "    \n",
    "\n",
    "print(train_features[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement brackets for test set \n",
    "\n",
    "\n",
    "\n",
    "#Age:{Under 12 years old, 12-24 years old, 25-44 years old , 45-64 years old , 65 or older} \n",
    "#Age is index 3\n",
    "for i in test_features:\n",
    "    get_age = int(i[2])\n",
    "    \n",
    "    if (get_age <= 11): #Under 12 years old\n",
    "        i[2] = \"Under 12 years old\" \n",
    "        continue\n",
    "        \n",
    "    if (12 <= get_age <= 24):\n",
    "        i[2] = \"12-24 years old\" \n",
    "        continue\n",
    "        \n",
    "    elif (25 <= get_age <= 44):\n",
    "        i[2] = \"25-44 years old\" \n",
    "        continue\n",
    "    \n",
    "    elif (45 <= get_age <= 64):\n",
    "        i[2] = \"45-64 years old\" \n",
    "        continue\n",
    "    \n",
    "    elif (get_age >= 65):\n",
    "        i[2] = \"65 years or older\" \n",
    "        continue\n",
    "  \n",
    "        \n",
    "    \n",
    "#now sibsp: { 0 members,  1-4 members,  5+  members}\n",
    "#sibsp is index 3\n",
    "for i in test_features:\n",
    "    get_sibsp = int(i[3])\n",
    "    \n",
    "    if(get_sibsp == 0):\n",
    "        i[3] = \"0 sibsp members\"\n",
    "    \n",
    "    elif(1 <= get_sibsp <= 4):\n",
    "        i[3] = \"1-4 sibsp members\"\n",
    "    \n",
    "    elif(get_sibsp >= 5):\n",
    "        i[3] = \"5+ sibsp members\"\n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# now parch:  0 members,  1-4 members,  5+  members\n",
    "#parch is index 4\n",
    "for i in test_features:\n",
    "    get_parch = int(i[4])\n",
    "    \n",
    "    if(get_parch  == 0):\n",
    "        i[4] = \"0 parch members\"\n",
    "    \n",
    "    elif(1 <= get_parch  <= 4):\n",
    "        i[4] = \"1-4 parch members\"\n",
    "    \n",
    "    elif(get_parch  >= 5):\n",
    "        i[4] = \"5+ parch members\"\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#now fare: { under 10,11-30, 31+}\n",
    "#fare is index 5\n",
    "for i in test_features:\n",
    "    get_fares = int(i[5])\n",
    "    \n",
    "    if (get_fares <= 10):\n",
    "        i[5] = \"Fare Under 10 \"\n",
    "    \n",
    "    elif (11 <= get_fares <= 30):\n",
    "        i[5] = \"Fare 11-30\"\n",
    "        \n",
    "    elif (get_fares >= 31):\n",
    "        i[5] = \"Fare 31+\"\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\citta\\anaconda3\\envs\\cs484\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\citta\\anaconda3\\envs\\cs484\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#revert the bracketed numpy train features to an df\n",
    "train_features = pd.DataFrame(train_features, columns=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])\n",
    "#encode the train features \n",
    "encoder= OneHotEncoder(sparse =False)\n",
    "train_features = encoder.fit_transform(train_features)\n",
    "\n",
    "\n",
    "\n",
    "#revert the bracketed numpy test features to an df\n",
    "test_features = pd.DataFrame(test_features, columns=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])\n",
    "#encode the test features \n",
    "test_features = encoder.fit_transform(test_features)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array of x_train: shape (712, 22)\n",
      "array of x_test: shape (179, 22)\n",
      "array of y_test: shape (712,)\n",
      "array of y_train: shape (179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#create a validations set for train\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
    "print('array of x_train: shape ' + str(np.shape(X_train)))\n",
    "print('array of x_test: shape ' + str(np.shape(X_test)))\n",
    "print('array of y_test: shape ' + str(np.shape(y_train)))\n",
    "print('array of y_train: shape ' + str(np.shape(y_test)))\n",
    "\n",
    "\n",
    "#to fix: ValueError: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
    "#the labels werent numbers before???\n",
    "y_train = y_train.astype(int)  \n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#making the file we submit to kagggle to check\n",
    "def make_csv_file(predictions, file_name):\n",
    "    rows =[] # fill it up with data then add it to our csv file\n",
    "    col_labels = [\"PassengerId\", \"Survived\"] #csv file col name \n",
    "    rows.append(col_labels)\n",
    "    for i in range (0, 418):\n",
    "        temp = [] \n",
    "        temp.append(test_passenger_id[i])\n",
    "        temp.append(predictions[i])\n",
    "        rows.append(temp)\n",
    "            \n",
    "    #finally create a csv file\n",
    "    with open(file_name, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(rows) #add our data \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the train set: 0.7877094972067039\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\citta\\TitanticDataset-2\\Team3.pynb.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/citta/TitanticDataset-2/Team3.pynb.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#lets try cross validation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/citta/TitanticDataset-2/Team3.pynb.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m five_fold \u001b[39m=\u001b[39m cross_val_score(model,X_train,y_train, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/citta/TitanticDataset-2/Team3.pynb.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFive Folds for training data:\u001b[39m\u001b[39m\"\u001b[39m, scores)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/citta/TitanticDataset-2/Team3.pynb.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m stats_five_fold_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(five_fold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/citta/TitanticDataset-2/Team3.pynb.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe min, max, avg of our 5 folds\u001b[39m\u001b[39m\"\u001b[39m, stats_five_fold_train\u001b[39m.\u001b[39mmin(), stats_five_fold_train\u001b[39m.\u001b[39mmax(), stats_five_fold_train\u001b[39m.\u001b[39mmean())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#log regression \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"The accuracy for the train set:\", accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(model,X_train,y_train, cv=5)\n",
    "print(\"Five Folds for training data:\", scores)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "# now onto the test set prediction \n",
    "test_predictions = model.predict(test_features)\n",
    "#submitted it to Kaggle (See the final report for the screenshot)\n",
    "make_csv_file(test_predictions, \"test_no_tuning_results.csv\") #make a csv file to submit to kaggle \n",
    "print(\"The accuracy for the test set: 0.76794\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning with Traning Set: L1/L2 Norms with different solver algs and 5 fold cross valdations:\n",
      "-------------------------------\n",
      "L1-liblinear: This is train accuracy: 0.7877094972067039\n",
      "L1-liblinear: Five Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.82394366]\n",
      "L1-liblinear: The min, max, avg of our 5 folds 0.7394366197183099 0.823943661971831 0.790692406185364\n",
      "-------------------------------\n",
      "L2-liblinear: This is train accuracy: 0.7877094972067039\n",
      "L2-liblinear: Five Folds for training data : [0.8041958  0.81118881 0.78169014 0.73943662 0.8028169 ]\n",
      "L2-liblinear: The min, max, avg of our 5 folds 0.7394366197183099 0.8111888111888111 0.7878656554712894\n",
      "-------------------------------\n",
      "L2-lbfgs: This is train accuracy: 0.7877094972067039\n",
      "L2-lbfgs: Five Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.8028169 ]\n",
      "L2-lbfgs: The min, max, avg of our 5 folds 0.7394366197183099 0.8111888111888111 0.7864670540726879\n",
      "-------------------------------\n",
      "L2-newton-cg: This is train accuracy: 0.7877094972067039\n",
      "L2-newton-cg: Five Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.8028169 ]\n",
      "L2-newton-cg: The min, max, avg of our 5 folds 0.7394366197183099 0.8111888111888111 0.7864670540726879\n",
      "-------------------------------\n",
      "L2-newton-cholesky: This is train accuracy: 0.7877094972067039\n",
      "L2-newton-cholesky: Five Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.8028169 ]\n",
      "L2-newton-cholesky: The min, max, avg of our 5 folds 0.7394366197183099 0.8111888111888111 0.7864670540726879\n",
      "-------------------------------\n",
      "L2-sag: This is train accuracy: 0.7877094972067039\n",
      "L2-sag: Five Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.8028169 ]\n",
      "L2-sag: The min, max, avg of our 5 folds 0.7394366197183099 0.8111888111888111 0.7864670540726879\n",
      "-------------------------------\n",
      "L1-saga: This is train accuracy: 0.7877094972067039\n",
      "L1-saga: Five Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.82394366]\n",
      "L1-saga: The min, max, avg of our 5 folds 0.7394366197183099 0.823943661971831 0.790692406185364\n",
      "-------------------------------\n",
      "L2-saga: This is train accuracy: 0.7877094972067039\n",
      "L2-saga: Five Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.8028169 ]\n",
      "L2-saga: The min, max, avg of our 5 folds 0.7394366197183099 0.8111888111888111 0.7864670540726879\n",
      "-------------------------------\n",
      "The best was: ('L1-liblinear', 0.790692406185364)\n"
     ]
    }
   ],
   "source": [
    "#tuning with different norms and solver algs \n",
    "#scitkit log regression documentation:\n",
    "'''\n",
    "Warning The choice of the algorithm depends on the penalty chosen. Supported penalties by solver:\n",
    "‘lbfgs’ - [‘l2’, None]\n",
    "\n",
    "‘liblinear’ - [‘l1’, ‘l2’]\n",
    "\n",
    "‘newton-cg’ - [‘l2’, None]\n",
    "\n",
    "‘newton-cholesky’ - [‘l2’, None]\n",
    "\n",
    "‘sag’ - [‘l2’, None]\n",
    "\n",
    "‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "all_solvers_penalty = []\n",
    "\n",
    "print(\"Tuning with Traning Set: L1/L2 Norms with different solver algs and 5 fold cross valdations:\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#L1 Regularization \n",
    "L1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "L1.fit(X_train, y_train) #use data from above \n",
    "L1_predict = L1.predict(X_test)\n",
    "L1_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L1-liblinear: This is train accuracy:\", L1_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L1,X_train,y_train, cv=5)\n",
    "print(\"L1-liblinear: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L1-liblinear: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L1-liblinear\",stats_five_fold_train.mean()))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "#L2 Regularization \n",
    "L2 = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-liblinear: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=5)\n",
    "print(\"L2-liblinear: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L2-liblinear: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L2-liblinear\",stats_five_fold_train.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#L2 Regularization \n",
    "L2 = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-lbfgs: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=5)\n",
    "print(\"L2-lbfgs: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L2-lbfgs: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L2-lbfgs\",stats_five_fold_train.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='newton-cg')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-newton-cg: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=5)\n",
    "print(\"L2-newton-cg: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L2-newton-cg: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L2-newton-c\",stats_five_fold_train.mean()))\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='newton-cholesky')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-newton-cholesky: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=5)\n",
    "print(\"L2-newton-cholesky: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L2-newton-cholesky: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L2-newton-cholesky\",stats_five_fold_train.mean()))\n",
    "\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='sag')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-sag: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=5)\n",
    "print(\"L2-sag: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L2-sag: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L2-sag\",stats_five_fold_train.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "#L1 Regularization \n",
    "L1 = LogisticRegression(penalty='l1', solver='saga')\n",
    "L1.fit(X_train, y_train) #use data from above \n",
    "L1_predict = L1.predict(X_test)\n",
    "L1_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L1-saga: This is train accuracy:\", L1_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L1,X_train,y_train, cv=5)\n",
    "print(\"L1-saga: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L1-saga: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L1-saga\",stats_five_fold_train.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='saga')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-saga: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=5)\n",
    "print(\"L2-saga: Five Folds for training data :\", five_fold)\n",
    "stats_five_fold_train = pd.Series(five_fold)\n",
    "print(\"L2-saga: The min, max, avg of our 5 folds\", stats_five_fold_train.min(), stats_five_fold_train.max(), stats_five_fold_train.mean())\n",
    "all_solvers_penalty.append((\"L2-saga\",stats_five_fold_train.mean()))\n",
    "print(\"-------------------------------\")\n",
    "#print(all_solvers_penalty)\n",
    "all_solvers_penalty1 = (sorted(all_solvers_penalty, key = lambda x: x[1]))\n",
    "print(\"The best was:\", all_solvers_penalty[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning with Traning Set: L1/L2 Norms with different solver algs and 3 fold cross valdations:\n",
      "-------------------------------\n",
      "L1-liblinear: This is train accuracy: 0.7877094972067039\n",
      "L1-liblinear: Three Folds for training data : [0.77310924 0.80168776 0.76793249]\n",
      "L1-liblinear: The min, max, avg of 3 folds 0.7679324894514767 0.8016877637130801 0.7809098322873452\n",
      "-------------------------------\n",
      "L2-liblinear: This is train accuracy: 0.7877094972067039\n",
      "L2-liblinear: Three Folds for training data : [0.77310924 0.80590717 0.7721519 ]\n",
      "L2-liblinear: The min, max, avg of 3 folds 0.7721518987341772 0.8059071729957806 0.7837227718091456\n",
      "-------------------------------\n",
      "L2-lbfgs: This is train accuracy: 0.7877094972067039\n",
      "L2-lbfgs: Three Folds for training data : [0.77310924 0.80590717 0.7721519 ]\n",
      "L2-lbfgs: The min, max, avg of 3 folds 0.7721518987341772 0.8059071729957806 0.7837227718091456\n",
      "-------------------------------\n",
      "L2-newton-cg: This is train accuracy: 0.7877094972067039\n",
      "L2-newton-cg: Three Folds for training data : [0.77310924 0.80590717 0.7721519 ]\n",
      "L2-newton-cg: The min, max, avg of 3 folds 0.7721518987341772 0.8059071729957806 0.7837227718091456\n",
      "-------------------------------\n",
      "L2-newton-cholesky: This is train accuracy: 0.7877094972067039\n",
      "L2-newton-cholesky: Three Folds for training data : [0.77310924 0.80590717 0.7721519 ]\n",
      "L2-newton-cholesky: The min, max, avg of 3 folds 0.7721518987341772 0.8059071729957806 0.7837227718091456\n",
      "-------------------------------\n",
      "L2-sag: This is train accuracy: 0.7877094972067039\n",
      "L2-sag: Three Folds for training data : [0.7972028  0.81118881 0.78169014 0.73943662 0.8028169 ]\n",
      "L2-sag: The min, max, avg of 3 folds 0.7721518987341772 0.8059071729957806 0.7837227718091456\n",
      "-------------------------------\n",
      "L1-saga: This is train accuracy: 0.7877094972067039\n",
      "L1-saga: Three Folds for training data : [0.77310924 0.80590717 0.7721519 ]\n",
      "L1-saga: The min, max, avg of 3 folds 0.7721518987341772 0.8059071729957806 0.7837227718091456\n",
      "-------------------------------\n",
      "L2-saga: This is train accuracy: 0.7877094972067039\n",
      "L2-saga: Three Folds for training data : [0.77310924 0.80590717 0.7721519 ]\n",
      "L2-saga: The min, max, avg of 3 folds 0.7721518987341772 0.8059071729957806 0.7837227718091456\n",
      "-------------------------------\n",
      "The best was: ('L1-liblinear', 0.7809098322873452)\n"
     ]
    }
   ],
   "source": [
    "#tuning with different norms and solver algs \n",
    "#scitkit log regression documentation:\n",
    "'''\n",
    "Warning The choice of the algorithm depends on the penalty chosen. Supported penalties by solver:\n",
    "‘lbfgs’ - [‘l2’, None]\n",
    "\n",
    "‘liblinear’ - [‘l1’, ‘l2’]\n",
    "\n",
    "‘newton-cg’ - [‘l2’, None]\n",
    "\n",
    "‘newton-cholesky’ - [‘l2’, None]\n",
    "\n",
    "‘sag’ - [‘l2’, None]\n",
    "\n",
    "‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "all_solvers_penalty = []\n",
    "\n",
    "print(\"Tuning with Traning Set: L1/L2 Norms with different solver algs and 3 fold cross valdations:\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#L1 Regularization \n",
    "L1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "L1.fit(X_train, y_train) #use data from above \n",
    "L1_predict = L1.predict(X_test)\n",
    "L1_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L1-liblinear: This is train accuracy:\", L1_accuracy)\n",
    "#lets try cross validation\n",
    "three_fold = cross_val_score(L1,X_train,y_train, cv=3)\n",
    "print(\"L1-liblinear: Three Folds for training data :\", three_fold)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L1-liblinear: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L1-liblinear\",three_folds.mean()))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "#L2 Regularization \n",
    "L2 = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-liblinear: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "three_fold = cross_val_score(L2,X_train,y_train, cv=3)\n",
    "print(\"L2-liblinear: Three Folds for training data :\", three_fold)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L2-liblinear: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L2-liblinear\",three_folds.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#L2 Regularization \n",
    "L2 = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-lbfgs: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "three_fold = cross_val_score(L2,X_train,y_train, cv=3)\n",
    "print(\"L2-lbfgs: Three Folds for training data :\", three_fold)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L2-lbfgs: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L2-lbfgs\",three_folds.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='newton-cg')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-newton-cg: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "three_fold = cross_val_score(L2,X_train,y_train, cv=3)\n",
    "print(\"L2-newton-cg: Three Folds for training data :\", three_fold)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L2-newton-cg: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L2-newton-c\",three_folds.mean()))\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='newton-cholesky')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-newton-cholesky: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "three_fold = cross_val_score(L2,X_train,y_train, cv=3)\n",
    "print(\"L2-newton-cholesky: Three Folds for training data :\", three_fold)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L2-newton-cholesky: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L2-newton-cholesky\",three_folds.mean()))\n",
    "\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='sag')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-sag: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=3)\n",
    "print(\"L2-sag: Three Folds for training data :\", scores)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L2-sag: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L2-sag\",three_folds.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "#L1 Regularization \n",
    "L1 = LogisticRegression(penalty='l1', solver='saga')\n",
    "L1.fit(X_train, y_train) #use data from above \n",
    "L1_predict = L1.predict(X_test)\n",
    "L1_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L1-saga: This is train accuracy:\", L1_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L1,X_train,y_train, cv=3)\n",
    "print(\"L1-saga: Three Folds for training data :\", three_fold)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L1-saga: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L1-saga\",three_folds.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='saga')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-saga: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "five_fold = cross_val_score(L2,X_train,y_train, cv=3)\n",
    "print(\"L2-saga: Three Folds for training data :\", three_fold)\n",
    "three_folds = pd.Series(three_fold)\n",
    "print(\"L2-saga: The min, max, avg of 3 folds\", three_folds.min(), three_folds.max(), three_folds.mean())\n",
    "all_solvers_penalty.append((\"L2-saga\",three_folds.mean()))\n",
    "print(\"-------------------------------\")\n",
    "all_solvers_penalty1 = (sorted(all_solvers_penalty, key = lambda x: x[1]))\n",
    "print(\"The best was:\", all_solvers_penalty[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning with Traning Set:L1/L2 Norms with different solver algs and 10 fold cross valdations:\n",
      "-------------------------------\n",
      "L1-liblinear: This is train accuracy: 0.7877094972067039\n",
      "L1-liblinear: Ten Folds for training data : [0.81944444 0.77777778 0.71830986 0.92957746 0.84507042 0.69014085\n",
      " 0.74647887 0.77464789 0.73239437 0.91549296]\n",
      "L1-liblinear: The min, max, avg of 10 folds 0.6901408450704225 0.9295774647887324 0.794933489827856\n",
      "-------------------------------\n",
      "L2-liblinear: This is train accuracy: 0.7877094972067039\n",
      "L2-liblinear: Ten Folds for training data : [0.81944444 0.79166667 0.71830986 0.92957746 0.84507042 0.70422535\n",
      " 0.73239437 0.77464789 0.71830986 0.91549296]\n",
      "L2-liblinear: The min, max, avg of 10 folds 0.704225352112676 0.9295774647887324 0.7949139280125196\n",
      "-------------------------------\n",
      "L2-lbfgs: This is train accuracy: 0.7877094972067039\n",
      "L2-lbfgs: Ten Folds for training data : [0.81944444 0.79166667 0.71830986 0.92957746 0.84507042 0.70422535\n",
      " 0.73239437 0.77464789 0.71830986 0.91549296]\n",
      "L2-lbfgs: The min, max, avg of 10 folds 0.704225352112676 0.9295774647887324 0.7949139280125196\n",
      "-------------------------------\n",
      "L2-newton-cg: This is train accuracy: 0.7877094972067039\n",
      "L2-newton-cg: Ten Folds for training data : [0.81944444 0.79166667 0.71830986 0.92957746 0.84507042 0.70422535\n",
      " 0.73239437 0.77464789 0.71830986 0.91549296]\n",
      "L2-newton-cg: The min, max, avg of 10 folds 0.704225352112676 0.9295774647887324 0.7949139280125196\n",
      "-------------------------------\n",
      "L2-newton-cholesky: This is train accuracy: 0.7877094972067039\n",
      "L2-newton-cholesky: Ten Folds for training data: [0.81944444 0.79166667 0.71830986 0.92957746 0.84507042 0.70422535\n",
      " 0.73239437 0.77464789 0.71830986 0.91549296]\n",
      "L2-newton-cholesky: The min, max, avg of 10 folds 0.704225352112676 0.9295774647887324 0.7949139280125196\n",
      "-------------------------------\n",
      "L2-sag: This is train accuracy: 0.7877094972067039\n",
      "L2-sag: ten_fold for training data : [0.81944444 0.79166667 0.71830986 0.92957746 0.84507042 0.70422535\n",
      " 0.73239437 0.77464789 0.71830986 0.91549296]\n",
      "L2-sag: The min, max, avg of 10 folds 0.704225352112676 0.9295774647887324 0.7949139280125196\n",
      "-------------------------------\n",
      "L1-saga: This is train accuracy: 0.7877094972067039\n",
      "L1-saga: Ten Folds for training data : [0.81944444 0.77777778 0.71830986 0.92957746 0.84507042 0.69014085\n",
      " 0.74647887 0.77464789 0.73239437 0.91549296]\n",
      "L1-saga: The min, max, avg of 10 folds 0.6901408450704225 0.9295774647887324 0.794933489827856\n",
      "-------------------------------\n",
      "L2-saga: This is train accuracy: 0.7877094972067039\n",
      "L2-saga: Ten Folds for training data : [0.81944444 0.79166667 0.71830986 0.92957746 0.84507042 0.70422535\n",
      " 0.73239437 0.77464789 0.71830986 0.91549296]\n",
      "L2-saga: The min, max, avg of 10 folds 0.704225352112676 0.9295774647887324 0.7949139280125196\n",
      "-------------------------------\n",
      "The best was: ('L1-liblinear', 0.794933489827856)\n"
     ]
    }
   ],
   "source": [
    "#tuning with different norms and solver algs \n",
    "#scitkit log regression documentation:\n",
    "'''\n",
    "Warning The choice of the algorithm depends on the penalty chosen. Supported penalties by solver:\n",
    "‘lbfgs’ - [‘l2’, None]\n",
    "\n",
    "‘liblinear’ - [‘l1’, ‘l2’]\n",
    "\n",
    "‘newton-cg’ - [‘l2’, None]\n",
    "\n",
    "‘newton-cholesky’ - [‘l2’, None]\n",
    "\n",
    "‘sag’ - [‘l2’, None]\n",
    "\n",
    "‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "all_solvers_penalty = []\n",
    "\n",
    "print(\"Tuning with Traning Set:L1/L2 Norms with different solver algs and 10 fold cross valdations:\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#L1 Regularization \n",
    "L1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "L1.fit(X_train, y_train) #use data from above \n",
    "L1_predict = L1.predict(X_test)\n",
    "L1_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L1-liblinear: This is train accuracy:\", L1_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold = cross_val_score(L1,X_train,y_train, cv=10)\n",
    "print(\"L1-liblinear: Ten Folds for training data :\", ten_fold)\n",
    "three_folds = pd.Series(ten_fold)\n",
    "print(\"L1-liblinear: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L1-liblinear\",ten_fold.mean()))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "#L2 Regularization \n",
    "L2 = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-liblinear: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold = cross_val_score(L2,X_train,y_train, cv=10)\n",
    "print(\"L2-liblinear: Ten Folds for training data :\", ten_fold)\n",
    "ten_fold = pd.Series(ten_fold)\n",
    "print(\"L2-liblinear: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L2-liblinear\",ten_fold.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#L2 Regularization \n",
    "L2 = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-lbfgs: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold = cross_val_score(L2,X_train,y_train, cv=10)\n",
    "print(\"L2-lbfgs: Ten Folds for training data :\", ten_fold)\n",
    "ten_folds = pd.Series(ten_fold)\n",
    "print(\"L2-lbfgs: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L2-lbfgs\",ten_fold.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='newton-cg')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-newton-cg: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold = cross_val_score(L2,X_train,y_train, cv=10)\n",
    "print(\"L2-newton-cg: Ten Folds for training data :\", ten_fold)\n",
    "ten_fold = pd.Series(ten_fold)\n",
    "print(\"L2-newton-cg: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L2-newton-c\",ten_fold.mean()))\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='newton-cholesky')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-newton-cholesky: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold = cross_val_score(L2,X_train,y_train, cv=10)\n",
    "print(\"L2-newton-cholesky: Ten Folds for training data:\", ten_fold)\n",
    "ten_fold = pd.Series(ten_fold)\n",
    "print(\"L2-newton-cholesky: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L2-newton-cholesky\",ten_fold.mean()))\n",
    "\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='sag')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-sag: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold= cross_val_score(L2,X_train,y_train, cv=10)\n",
    "print(\"L2-sag: ten_fold for training data :\", ten_fold)\n",
    "ten_fold = pd.Series(ten_fold)\n",
    "print(\"L2-sag: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L2-sag\",ten_fold.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "#L1 Regularization \n",
    "L1 = LogisticRegression(penalty='l1', solver='saga')\n",
    "L1.fit(X_train, y_train) #use data from above \n",
    "L1_predict = L1.predict(X_test)\n",
    "L1_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L1-saga: This is train accuracy:\", L1_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold = cross_val_score(L1,X_train,y_train, cv=10)\n",
    "print(\"L1-saga: Ten Folds for training data :\", ten_fold)\n",
    "ten_fold = pd.Series(ten_fold)\n",
    "print(\"L1-saga: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L1-saga\",ten_fold.mean()))\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "L2 = LogisticRegression(penalty='l2', solver='saga')\n",
    "L2.fit(X_train, y_train) #use data from above \n",
    "L2_predict = L2.predict(X_test)\n",
    "L2_accuracy =  accuracy_score(y_test, y_predict)\n",
    "print(\"L2-saga: This is train accuracy:\", L2_accuracy)\n",
    "#lets try cross validation\n",
    "ten_fold= cross_val_score(L2,X_train,y_train, cv=10)\n",
    "print(\"L2-saga: Ten Folds for training data :\", ten_fold)\n",
    "ten_fold = pd.Series(ten_fold)\n",
    "print(\"L2-saga: The min, max, avg of 10 folds\", ten_fold.min(), ten_fold.max(), ten_fold.mean())\n",
    "all_solvers_penalty.append((\"L2-saga\",ten_fold.mean()))\n",
    "print(\"-------------------------------\")\n",
    "all_solvers_penalty1 = (sorted(all_solvers_penalty, key = lambda x: x[1]))\n",
    "print(\"The best was:\", all_solvers_penalty[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After tuning it seems like the best model is Log Regression: L1-liblinear with 10 folds\n",
      "The accuracy of the test set after tuning is: 0.76076\n"
     ]
    }
   ],
   "source": [
    "print(\"After tuning it seems like the best model is Log Regression: L1-liblinear with 10 folds\")\n",
    "\n",
    "L1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "L1.fit(X_train, y_train) #use data from above \n",
    "L1_predict_test = L1.predict(test_features)\n",
    "make_csv_file(L1_predict_test, \"test_set_after_tuning.csv\")\n",
    "\n",
    "print(\"The accuracy of the test set after tuning is: 0.76076\") #sumbitted to kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're creating the dataframe from the tested set to find out the most common characteristics from our survivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "survivors = pd.read_csv(\"test.csv\")\n",
    "survived = pd.read_csv(\"test_set_after_tuning.csv\")\n",
    "survived = survived[\"Survived\"]\n",
    "survivors.insert(2, \"Survived\",survived,False)\n",
    "survivors = survivors.sort_values(by=['Survived'], ascending=False)\n",
    "survivors.to_csv(\"sorted_test_survivors.csv\")\n",
    "survivors.describe()\n",
    "survivors['Sex'].mode()\n",
    "survivors['Pclass'].mode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
